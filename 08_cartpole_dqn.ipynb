{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cartpole DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Q-Learning Network with Keras and OpenAI Gym, based on [Keon Kim's code](https://github.com/keon/deep-q-learning/blob/master/dqn.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam, SGD\n",
    "import os # for creating directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1') # initialise environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_size = env.observation_space.shape[0]\n",
    "state_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_size = env.action_space.n\n",
    "action_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_episodes = 1001 # n games we want agent to play (default 1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'model_output/cartpole/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000) # double-ended queue; acts like list, but elements can be added/removed from either end\n",
    "        self.gamma = 0.95                # decay or discount rate: enables agent to take into account future actions in addition to the immediate ones, but discounted at this rate\n",
    "        self.epsilon = 1.0               # exploration rate: how much to act randomly; more initially than later due to epsilon decay\n",
    "        self.epsilon_decay = 0.995       # decrease number of random explorations as the agent's performance (hopefully) improves over time\n",
    "        self.epsilon_min = 0.01          # minimum amount of random exploration permitted\n",
    "        self.learning_rate = 0.001       # rate at which NN adjusts models parameters via SGD to reduce cost \n",
    "        self.model = self._build_model() # private method \n",
    "    \n",
    "    def _build_model(self):\n",
    "        # neural net to approximate Q-value function:\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu')) # 1st hidden layer; states as input\n",
    "        model.add(Dense(24, activation='relu'))                            # 2nd hidden layer\n",
    "        model.add(Dense(self.action_size, activation='linear'))            # 2 actions, so 2 output neurons: 0 and 1 (L/R)\n",
    "        model.compile(loss='mse', optimizer=SGD(learning_rate=self.learning_rate))\n",
    "        return model\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done)) # list of previous experiences, enabling re-training later\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:   # if acting randomly, take random action\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state, verbose=0) # if not acting randomly, predict reward value based on current state\n",
    "        return np.argmax(act_values[0])        # pick the action that will give the highest reward (i.e., go left or right?)\n",
    "\n",
    "    def replay(self, batch_size): # method that trains NN with experiences sampled from memory\n",
    "        minibatch = random.sample(self.memory, batch_size)         # sample a minibatch from memory\n",
    "        for state, action, reward, next_state, done in minibatch:  # extract data for each minibatch sample\n",
    "            target = reward  # if done (boolean whether game ended or not, i.e., whether final state or not), then target = reward\n",
    "            if not done:     # if not done, then predict future discounted reward\n",
    "                target = (reward + self.gamma *     # (target) = reward + (discount rate gamma) * \n",
    "                          np.amax(self.model.predict(next_state, verbose=0)[0])) # (maximum target Q based on future action a')\n",
    "            target_f = self.model.predict(state, verbose=0)    # approximately map current state to future discounted reward\n",
    "            target_f[0][action] = target\n",
    "            print(state, target_f)\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0) # single epoch of training with x=state, y=target_f; fit decreases loss btwn target_f and y_hat\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interact with environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DQNAgent(state_size, action_size) # initialise agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0/1001, score: 25, e: 1.0\n",
      "episode: 1/1001, score: 10, e: 1.0\n",
      "[[ 0.0165385  -0.19096363  0.00935776  0.34361774]] [[0.02050916 1.0003213 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 09:40:12.844628: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:435] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2025-05-12 09:40:12.845181: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:624 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "2025-05-12 09:40:12.847731: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:435] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2025-05-12 09:40:12.848272: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:624 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "2025-05-12 09:40:12.850746: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:435] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2025-05-12 09:40:12.851249: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:624 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "2025-05-12 09:40:12.853620: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:435] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2025-05-12 09:40:12.854192: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:624 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "2025-05-12 09:40:12.857249: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:435] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2025-05-12 09:40:12.857917: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:624 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "2025-05-12 09:40:12.860509: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:435] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2025-05-12 09:40:12.861037: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:624 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Graph execution error:\n\nDetected at node SGD/StatefulPartitionedCall_4 defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 978, in launch_instance\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_cell\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3139, in run_cell_async\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3318, in run_ast_nodes\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n\n  File \"/tmp/ipykernel_130504/4031564917.py\", line 21, in <module>\n\n  File \"/tmp/ipykernel_130504/2135914291.py\", line 41, in replay\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1783, in fit\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1377, in train_function\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1360, in step_function\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1349, in run_step\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1130, in train_step\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 544, in minimize\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1223, in apply_gradients\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 652, in apply_gradients\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1253, in _internal_apply_gradients\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1345, in _distributed_apply_gradients_fn\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1340, in apply_grad_to_update_var\n\nDNN library initialization failed. Look at the errors above for more details.\n\t [[{{node SGD/StatefulPartitionedCall_4}}]] [Op:__inference_train_function_3174]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [29], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m \u001b[38;5;66;03m# exit loop\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(agent\u001b[38;5;241m.\u001b[39mmemory) \u001b[38;5;241m>\u001b[39m batch_size:\n\u001b[0;32m---> 21\u001b[0m     \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# train the agent by replaying the experiences of the episode\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m e \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m50\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     24\u001b[0m     agent\u001b[38;5;241m.\u001b[39msave(output_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{:04d}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn [27], line 41\u001b[0m, in \u001b[0;36mDQNAgent.replay\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     39\u001b[0m     target_f[\u001b[38;5;241m0\u001b[39m][action] \u001b[38;5;241m=\u001b[39m target\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(state, target_f)\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# single epoch of training with x=state, y=target_f; fit decreases loss btwn target_f and y_hat\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon_min:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon_decay\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Graph execution error:\n\nDetected at node SGD/StatefulPartitionedCall_4 defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 978, in launch_instance\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_cell\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3139, in run_cell_async\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3318, in run_ast_nodes\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n\n  File \"/tmp/ipykernel_130504/4031564917.py\", line 21, in <module>\n\n  File \"/tmp/ipykernel_130504/2135914291.py\", line 41, in replay\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1783, in fit\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1377, in train_function\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1360, in step_function\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1349, in run_step\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1130, in train_step\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 544, in minimize\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1223, in apply_gradients\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 652, in apply_gradients\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1253, in _internal_apply_gradients\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1345, in _distributed_apply_gradients_fn\n\n  File \"/home/marcel/.local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1340, in apply_grad_to_update_var\n\nDNN library initialization failed. Look at the errors above for more details.\n\t [[{{node SGD/StatefulPartitionedCall_4}}]] [Op:__inference_train_function_3174]"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "for e in range(n_episodes):   # iterate over new episodes of the game\n",
    "    state = env.reset()       # reset state at start of each new episode of the game\n",
    "    state = np.reshape(state[0], [1, state_size])\n",
    "    \n",
    "    for time in range(5000):  # time represents a frame of the game; goal is to keep pole upright as long as possible up to range, e.g., 500 or 5000 timesteps\n",
    "\n",
    "        action = agent.act(state)   # action is either 0 or 1 (move cart left or right); decide on one or other here\n",
    "        next_state, reward, done, _, _ = env.step(action) # agent interacts with env, gets feedback; 4 state data points, e.g., pole angle, cart position        \n",
    "        \n",
    "        reward = reward if not done else -10           # reward +1 for each additional frame with pole upright        \n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "        agent.remember(state, action, reward, next_state, done) # remember the previous timestep's state, actions, reward, etc.        \n",
    "        state = next_state     # set \"current state\" for upcoming iteration to the current next state        \n",
    "        if done:               # episode ends if agent drops pole or we reach timestep 5000\n",
    "            print(\"episode: {}/{}, score: {}, e: {:.2}\" # print the episode's score and agent's epsilon\n",
    "                  .format(e, n_episodes, time, agent.epsilon))\n",
    "            break # exit loop\n",
    "            \n",
    "    if len(agent.memory) > batch_size:\n",
    "        agent.replay(batch_size) # train the agent by replaying the experiences of the episode\n",
    "        \n",
    "    if e % 50 == 0:\n",
    "        agent.save(output_dir + \"weights_\" + '{:04d}'.format(e) + \".hdf5\")         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
