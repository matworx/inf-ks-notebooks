{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d044862",
   "metadata": {},
   "source": [
    "# Build GPT from scratch\n",
    "\n",
    "taken from Video from Andrej Karpathy (https://www.youtube.com/watch?v=kCc8FmEb1nY)\n",
    "\n",
    "We use the tiny_shapespeare.txt data.\n",
    "\n",
    "References are:\n",
    "* https://arxiv.org/pdf/1706.03762.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fefc4da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with  open('data/shakespeare/input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6f9f596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset:  1115394\n"
     ]
    }
   ],
   "source": [
    "print('length of dataset: ', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e9c7965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a903b87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "# vocabulary\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11e52332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 43, 50, 50, 53, 1, 35, 53, 56, 50, 42, 2]\n",
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "# create mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars)}\n",
    "itos = { i:ch for i,ch in enumerate(chars)}\n",
    "\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n",
    "\n",
    "print(encode(\"Hello World!\"))\n",
    "print(decode(encode(\"Hello World!\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc49943",
   "metadata": {},
   "source": [
    "Alternate tokinizers:\n",
    "* SentencePiece: https://github.com/google/sentencepiece\n",
    "* TikToken (used by openAI): https://github.com/openai/tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "490a296b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: org.freedesktop.DBus.Error.InvalidFileContent: D-Bus library appears to be incorrectly set up: see the manual page for dbus-uuidgen to correct this issue. (Failed to open \"/var/lib/dbus/machine-id\": No such file or directory; UUID file '/etc/machine-id' should contain a hex string of length 32, not length 0, with no other text)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tiktoken (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for tiktoken\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca9d29cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tiktoken'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-55240e44c69f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtiktoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtiktoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gpt2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tiktoken'"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.get_encoding('gpt2')\n",
    "print(enc.n_vocab)\n",
    "\n",
    "print(enc.encode(\"Hello World!\"))\n",
    "\n",
    "print(enc.decode(enc.encode(\"Hello World!\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9477dd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d992179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train and validation (90/10)\n",
    "\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "331a1f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size=8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb9f436e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18]) tensor(47)\n",
      "tensor([18, 47]) tensor(56)\n",
      "tensor([18, 47, 56]) tensor(57)\n",
      "tensor([18, 47, 56, 57]) tensor(58)\n",
      "tensor([18, 47, 56, 57, 58]) tensor(1)\n",
      "tensor([18, 47, 56, 57, 58,  1]) tensor(15)\n",
      "tensor([18, 47, 56, 57, 58,  1, 15]) tensor(47)\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47]) tensor(58)\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1] \n",
    "for t in range(block_size):\n",
    "    ctx = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(ctx, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06014650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:   torch.Size([4, 8]) tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "targets:  torch.Size([4, 8]) tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "--\n",
      "tensor([24]) tensor(43)\n",
      "tensor([24, 43]) tensor(58)\n",
      "tensor([24, 43, 58]) tensor(5)\n",
      "tensor([24, 43, 58,  5]) tensor(57)\n",
      "tensor([24, 43, 58,  5, 57]) tensor(1)\n",
      "tensor([24, 43, 58,  5, 57,  1]) tensor(46)\n",
      "tensor([24, 43, 58,  5, 57,  1, 46]) tensor(43)\n",
      "tensor([24, 43, 58,  5, 57,  1, 46, 43]) tensor(39)\n",
      "tensor([44]) tensor(53)\n",
      "tensor([44, 53]) tensor(56)\n",
      "tensor([44, 53, 56]) tensor(1)\n",
      "tensor([44, 53, 56,  1]) tensor(58)\n",
      "tensor([44, 53, 56,  1, 58]) tensor(46)\n",
      "tensor([44, 53, 56,  1, 58, 46]) tensor(39)\n",
      "tensor([44, 53, 56,  1, 58, 46, 39]) tensor(58)\n",
      "tensor([44, 53, 56,  1, 58, 46, 39, 58]) tensor(1)\n",
      "tensor([52]) tensor(58)\n",
      "tensor([52, 58]) tensor(1)\n",
      "tensor([52, 58,  1]) tensor(58)\n",
      "tensor([52, 58,  1, 58]) tensor(46)\n",
      "tensor([52, 58,  1, 58, 46]) tensor(39)\n",
      "tensor([52, 58,  1, 58, 46, 39]) tensor(58)\n",
      "tensor([52, 58,  1, 58, 46, 39, 58]) tensor(1)\n",
      "tensor([52, 58,  1, 58, 46, 39, 58,  1]) tensor(46)\n",
      "tensor([25]) tensor(17)\n",
      "tensor([25, 17]) tensor(27)\n",
      "tensor([25, 17, 27]) tensor(10)\n",
      "tensor([25, 17, 27, 10]) tensor(0)\n",
      "tensor([25, 17, 27, 10,  0]) tensor(21)\n",
      "tensor([25, 17, 27, 10,  0, 21]) tensor(1)\n",
      "tensor([25, 17, 27, 10,  0, 21,  1]) tensor(54)\n",
      "tensor([25, 17, 27, 10,  0, 21,  1, 54]) tensor(39)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "batch_size = 4 # number of independent sequences processed in parallel \n",
    "block_size = 8 # context length\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x  = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y  = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "\n",
    "print('inputs:  ', xb.shape, xb)\n",
    "print('targets: ', yb.shape, yb)\n",
    "print('--')\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        ctx = xb[b,:t+1]\n",
    "        target = yb[b, t]\n",
    "        print(ctx, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad387b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.8786, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "SKIcLT;AcELMoTbvZv C?nq-QE33:CJqkOKH-q;:la!oiywkHjgChzbQ?u!3bLIgwevmyFJGUGp\n",
      "wnYWmnxKWWev-tDqXErVKLgJ\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reas off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        \n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_token):\n",
    "        # idx is (B, T) array of indices in the ctx\n",
    "        for _ in range(max_new_token):\n",
    "            # get predictions    \n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax\n",
    "            probs = F.softmax(logits, dim=-1) # (B,C)\n",
    "            # sample from distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B,1)\n",
    "            # append \n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "    \n",
    "m = BigramLanguageModel(vocab_size)\n",
    "\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(m.generate(idx, max_new_token=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b36962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4be5475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.382369041442871\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "\n",
    "for steps in range(10000):\n",
    "    \n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "    \n",
    "    # evaluate th eloss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ac8036c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lso br. ave aviasurf my, yxMPZI ivee iuedrd whar ksth y h bora s be hese, woweee; the! KI 'de, ulseecherd d o blllando;LUCEO, oraingofof win!\n",
      "RIfans picspeserer hee tha,\n",
      "TOFonk? me ain ckntoty ded. bo'llll st ta d:\n",
      "ELIS me hurf lal y, ma dus pe athouo\n",
      "BEY:! Indy; by s afreanoo adicererupa anse tecorro llaus a!\n",
      "OLeneerithesinthengove fal amas trr\n",
      "TI ar I t, mes, n IUSt my w, fredeeyove\n",
      "THek' merer, dd\n",
      "We ntem lud engitheso; cer ize helorowaginte the?\n",
      "Thak orblyoruldvicee chot, p,\n",
      "Bealivolde Th li\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx, max_new_token=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80ff68f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# towards self-attention\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "B,T,C = 4,8,32\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0263f0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want x[b,t] = mean_{i<=t} x[b,i]\n",
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] # (t,c)\n",
    "        xbow[b,t] = torch.mean(xprev,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aea3ed6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8077e-01, -6.9988e-02, -3.5962e-01, -9.1520e-01,  6.2577e-01,\n",
       "          2.5510e-02,  9.5451e-01,  6.4349e-02,  3.6115e-01,  1.1679e+00,\n",
       "         -1.3499e+00, -5.1018e-01,  2.3596e-01, -2.3978e-01, -9.2111e-01,\n",
       "          1.5433e+00,  1.3488e+00, -1.3964e-01,  2.8580e-01,  9.6512e-01,\n",
       "         -2.0371e+00,  4.9314e-01,  1.4870e+00,  5.9103e-01,  1.2603e-01,\n",
       "         -1.5627e+00, -1.1601e+00, -3.3484e-01,  4.4777e-01, -8.0164e-01,\n",
       "          1.5236e+00,  2.5086e+00],\n",
       "        [-2.4116e-01, -1.6063e-01,  3.2526e-01, -3.9683e-01,  3.9208e-01,\n",
       "          5.7976e-01, -9.9692e-02, -1.1702e-01, -7.3193e-02,  1.2198e-01,\n",
       "         -4.0159e-01, -1.0025e+00, -4.8488e-01,  1.6602e-01, -7.5923e-01,\n",
       "          4.2481e-01,  1.4972e+00, -4.7132e-01,  8.1860e-01,  3.4460e-01,\n",
       "         -1.7740e+00,  1.2990e+00,  2.1250e+00, -5.7775e-01,  7.8881e-01,\n",
       "         -1.5365e+00, -1.6947e-01, -2.7318e-01,  6.1334e-01,  3.6581e-01,\n",
       "          1.5667e+00,  1.0527e+00],\n",
       "        [-4.3893e-01,  9.2179e-02,  1.9971e-01, -2.8607e-01,  9.5720e-02,\n",
       "          5.4176e-01, -1.5221e-01, -4.3377e-01,  6.2085e-01, -9.7673e-02,\n",
       "         -1.9346e-01, -4.3597e-01, -7.9881e-01,  4.1266e-01, -4.5796e-01,\n",
       "          3.5921e-01,  1.8281e+00, -7.2210e-01,  8.8263e-01,  4.1507e-01,\n",
       "         -1.7138e+00,  4.4242e-01,  1.6468e+00, -4.5054e-01,  6.4084e-01,\n",
       "         -1.1383e+00,  4.5641e-02, -4.3757e-01,  2.6924e-01,  9.8210e-02,\n",
       "          7.1071e-01,  5.6531e-01],\n",
       "        [-7.4593e-01, -2.7215e-01,  1.0840e-01,  2.6009e-02,  7.9677e-02,\n",
       "          2.2085e-01, -1.8861e-01, -3.2104e-01,  4.2133e-01, -1.0661e-01,\n",
       "         -7.1608e-02,  1.9264e-02, -5.6888e-01,  9.4494e-01, -5.0358e-01,\n",
       "         -2.2410e-01,  1.2887e+00, -5.3959e-01,  8.9353e-01, -1.5984e-01,\n",
       "         -1.2436e+00,  4.4647e-01,  7.9352e-01, -1.9141e-01,  9.1839e-01,\n",
       "         -7.8353e-01,  1.1197e-01, -4.9162e-01,  3.7520e-02,  1.5327e-01,\n",
       "          3.9564e-01,  5.7752e-02],\n",
       "        [-1.0078e+00,  1.4777e-01,  3.4742e-01, -6.9219e-02,  3.3317e-01,\n",
       "          5.1487e-01, -1.7578e-01, -5.9330e-01,  3.3174e-01, -7.0480e-02,\n",
       "          1.5306e-01,  1.5099e-01, -3.9377e-01,  6.0651e-01, -2.5417e-01,\n",
       "         -1.7462e-03,  1.4884e+00, -2.3944e-01,  4.0888e-01, -1.8612e-01,\n",
       "         -1.0177e+00,  2.9444e-01,  5.0895e-01,  7.4572e-02,  5.3646e-01,\n",
       "         -5.9283e-01,  3.3455e-01, -4.4020e-01, -1.8142e-01, -8.2378e-03,\n",
       "          6.3469e-01, -9.3697e-02],\n",
       "        [-9.8921e-01,  1.3417e-01,  2.8014e-01,  3.3252e-01, -1.7627e-01,\n",
       "          5.1401e-01, -2.8222e-01, -5.3542e-01,  2.7721e-01,  2.8250e-01,\n",
       "          1.0129e-01,  8.9380e-02, -5.5346e-01,  4.9588e-01, -5.2080e-01,\n",
       "         -2.3227e-01,  1.1828e+00, -3.9329e-01,  3.6482e-01, -1.2738e-01,\n",
       "         -7.2296e-01,  3.9757e-01,  1.3617e-01,  2.7973e-01,  6.0694e-01,\n",
       "         -3.1736e-01,  3.8377e-01, -5.8128e-01, -2.6576e-01,  3.4951e-01,\n",
       "          6.1414e-01,  1.2510e-01],\n",
       "        [-8.2062e-01,  6.6077e-02,  4.9662e-01,  4.8380e-01,  2.9885e-03,\n",
       "          3.5273e-01, -3.0746e-01, -3.7787e-01,  2.4022e-01,  4.8829e-03,\n",
       "          2.4638e-01,  1.5085e-01, -6.5187e-01,  2.8763e-01, -4.5855e-01,\n",
       "         -1.8215e-01,  1.0565e+00, -4.4087e-01,  2.6815e-01, -1.7433e-01,\n",
       "         -5.2767e-01,  4.2752e-01,  2.9381e-01,  3.4441e-01,  5.9226e-01,\n",
       "         -1.4755e-01,  2.8978e-01, -6.0494e-01, -3.1111e-01,  3.5242e-01,\n",
       "          4.4703e-01,  5.0332e-02],\n",
       "        [-7.9077e-01,  3.0213e-02,  4.3624e-01,  3.8511e-01, -1.1831e-03,\n",
       "          4.1134e-01, -2.6898e-01, -3.8656e-01,  3.1274e-01, -1.8545e-01,\n",
       "          2.9257e-01, -1.0111e-01, -6.9260e-01,  2.5958e-01, -4.5808e-01,\n",
       "         -2.1123e-01,  1.1117e+00, -3.9074e-01,  1.3399e-01, -2.9784e-01,\n",
       "         -4.0832e-01,  3.3884e-01,  2.5549e-01,  1.9162e-01,  4.7791e-01,\n",
       "         -1.0623e-01,  1.3727e-01, -6.8542e-01, -1.3233e-01,  6.9874e-02,\n",
       "          3.2521e-01,  1.7912e-01]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]\n",
    "xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53993d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias= False)\n",
    "query = nn.Linear(C, head_size, bias= False)\n",
    "value = nn.Linear(C, head_size, bias= False)\n",
    "k = key(x)   # (B,T, 16)\n",
    "q = query(x) # (B,T, 16)\n",
    "wei = q @ k.transpose(-2, -1) # (B,T,16) @ (B, 16, T) ---> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "\n",
    "wei  = wei.masked_fill(tril ==0, float('-inf'))\n",
    "\n",
    "wei  = F.softmax(wei, dim=-1)\n",
    "Z= wei @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9a583b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tril = torch.tril(torch.ones(T,T))\n",
    "#wei  = torch.zeros((T,T))\n",
    "wei  = wei.masked_fill(tril ==0, float('-inf'))\n",
    "wei  = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "\n",
    "out = wei @ x\n",
    "out = wei @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "579540b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
       "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
       "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f19ab8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1571,  0.8801,  0.1615, -0.7824, -0.1429,  0.7468,  0.1007, -0.5239,\n",
       "         -0.8873,  0.1907,  0.1762, -0.5943, -0.4812, -0.4860,  0.2862,  0.5710],\n",
       "        [ 0.6764, -0.5477, -0.2478,  0.3143, -0.1280, -0.2952, -0.4296, -0.1089,\n",
       "         -0.0493,  0.7268,  0.7130, -0.1164,  0.3266,  0.3431, -0.0710,  1.2716],\n",
       "        [ 0.4823, -0.1069, -0.4055,  0.1770,  0.1581, -0.1697,  0.0162,  0.0215,\n",
       "         -0.2490, -0.3773,  0.2787,  0.1629, -0.2895, -0.0676, -0.1416,  1.2194],\n",
       "        [ 0.1971,  0.2856, -0.1303, -0.2655,  0.0668,  0.1954,  0.0281, -0.2451,\n",
       "         -0.4647,  0.0693,  0.1528, -0.2032, -0.2479, -0.1621,  0.1947,  0.7678],\n",
       "        [ 0.2510,  0.7346,  0.5939,  0.2516,  0.2606,  0.7582,  0.5595,  0.3539,\n",
       "         -0.5934, -1.0807, -0.3111, -0.2781, -0.9054,  0.1318, -0.1382,  0.6371],\n",
       "        [ 0.3428,  0.4960,  0.4725,  0.3028,  0.1844,  0.5814,  0.3824,  0.2952,\n",
       "         -0.4897, -0.7705, -0.1172, -0.2541, -0.6892,  0.1979, -0.1513,  0.7666],\n",
       "        [ 0.1866, -0.0964, -0.1430,  0.3059,  0.0834, -0.0069, -0.2047, -0.1535,\n",
       "         -0.0762,  0.3269,  0.3090,  0.0766,  0.0992,  0.1656,  0.1975,  0.7625],\n",
       "        [ 0.1301, -0.0328, -0.4965,  0.2865,  0.2704, -0.2636, -0.0738,  0.3786,\n",
       "          0.0746,  0.0338,  0.0147,  0.3194,  0.2993, -0.1653, -0.0386,  0.3375]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc109485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 65])\n",
      "tensor(4.1999, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "ee'nCXLFs?Z,gfrx.dJ$tRFCEun U3pmPej3Pt-y?'SwrWl!$K-:I,IwIR$&,?cNIUN'wONtErKcfjmKZvF,GvpzGweVoHSrQJs,\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "\n",
    "n_embd= 32\n",
    "\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, head size)\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,hs)\n",
    "        q = self.query(x) # (B,T,hs)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        return out\n",
    "\n",
    "class BigramLanguageModel2(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reas off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.sa_head = Head(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        \n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_embed = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_embed = self.position_embedding_table(torch.arange(T)) # (T,C)\n",
    "        x= tok_embed + pos_embed\n",
    "        x=self.sa_head(x)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_token):\n",
    "        # idx is (B, T) array of indices in the ctx\n",
    "        for _ in range(max_new_token):\n",
    "            idx_conds = idx[:, -block_size:]\n",
    "            # get predictions    \n",
    "            logits, loss = self(idx_conds)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax\n",
    "            probs = F.softmax(logits, dim=-1) # (B,C)\n",
    "            # sample from distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B,1)\n",
    "            # append \n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "    \n",
    "m = BigramLanguageModel2()\n",
    "\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(m.generate(idx, max_new_token=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d198ec48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3033900260925293\n"
     ]
    }
   ],
   "source": [
    "# create optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
    "batch_size=32\n",
    "\n",
    "for steps in range(10000):\n",
    "    \n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "    \n",
    "    # evaluate th eloss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d668ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Turl-chee\n",
      "'A Pout;\n",
      "I myoum, yousshou tand hererord oche ty Xas faur ciuprue:\n",
      "Hot as thaillgout mandd\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(m.generate(idx, max_new_token=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "081822fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 65])\n",
      "tensor(4.2469, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "VG,vRG:ylxdtbnHA;,ea$Pc,qO$kX!Iky!Xf;,!jDC$EmZ'TSsjdBszJ& -EFOHcfMxUc$QnkJXuWT,$cjTy'kSB,&rK$MNw,Lpm\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        #self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        #self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        #out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class BigramLanguageModel3(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reas off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.sa_head = MultiHeadAttention(4, n_embd//4)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        \n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_embed = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_embed = self.position_embedding_table(torch.arange(T)) # (T,C)\n",
    "        x= tok_embed + pos_embed\n",
    "        x=self.sa_head(x)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_token):\n",
    "        # idx is (B, T) array of indices in the ctx\n",
    "        for _ in range(max_new_token):\n",
    "            idx_conds = idx[:, -block_size:]\n",
    "            # get predictions    \n",
    "            logits, loss = self(idx_conds)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax\n",
    "            probs = F.softmax(logits, dim=-1) # (B,C)\n",
    "            # sample from distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B,1)\n",
    "            # append \n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "    \n",
    "m = BigramLanguageModel3()\n",
    "\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(m.generate(idx, max_new_token=100)[0].tolist()))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4c258fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0846638679504395\n"
     ]
    }
   ],
   "source": [
    "# create optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
    "batch_size=32\n",
    "\n",
    "for steps in range(10000):\n",
    "    \n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "    \n",
    "    # evaluate th eloss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c62fb24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QUEN, I toone soun bouet Sell sent, hee suge.\n",
      "\n",
      "Ither anltt ther dearcathe Yihestor heighh ou houldee.\n",
      "\n",
      "Nombleraciove:\n",
      "Ed To Jo-shacerut as herers dien thore! wichave beaposss.\n",
      "O: my pin:\n",
      "Aard:\n",
      "Hy whout Es DO tho:\n",
      "Por chow thruo inn faltat deth wirds kf\n",
      "OuF Ber may lastish, let donty my tas so thoud su orthou sto gral halll eand hould Bilen I,\n",
      "USeck Huls useiferp?\n",
      "For thertu.'\n",
      "Fa gapu of, beegt kin'd sho isild try, loster moll,\n",
      "El:\n",
      "Wingulde, lence hircand the lorrd he will color-sp\n",
      "he as\n",
      "If the I\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(m.generate(idx, max_new_token=500)[0].tolist()))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b388f038",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            #nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class BigramLanguageModel4(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reas off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.sa_head = MultiHeadAttention(4, n_embd//4)\n",
    "        self.fwd = FeedFoward(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        \n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_embed = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_embed = self.position_embedding_table(torch.arange(T)) # (T,C)\n",
    "        x = tok_embed + pos_embed\n",
    "        x = self.sa_head(x)\n",
    "        x = self.fwd(x)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_token):\n",
    "        # idx is (B, T) array of indices in the ctx\n",
    "        for _ in range(max_new_token):\n",
    "            idx_conds = idx[:, -block_size:]\n",
    "            # get predictions    \n",
    "            logits, loss = self(idx_conds)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax\n",
    "            probs = F.softmax(logits, dim=-1) # (B,C)\n",
    "            # sample from distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B,1)\n",
    "            # append \n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "    \n",
    "m = BigramLanguageModel4()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d05210fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.111990451812744\n"
     ]
    }
   ],
   "source": [
    "# create optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
    "batch_size=32\n",
    "\n",
    "for steps in range(10000):\n",
    "    \n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "    \n",
    "    # evaluate th eloss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3138867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ther spe; no ade: hate a for to?\n",
      "SO:\n",
      "O what i\n",
      "Is chais,\n",
      "out then be no botal for miess, wicie,\n",
      "As me preaday:\n",
      "Bye\n",
      "Tho prost thak have,\n",
      "Four uparpon by me, do frome yest,\n",
      "Now's poted, and you care.\n",
      "\n",
      "BUCHESTELLO:\n",
      "Eld; I camjark par,\n",
      "Secay, I and his liabe in dowo,\n",
      "Fir;\n",
      "Wo:\n",
      "My pred yest;\n",
      "And shall\n",
      "I wich thatthe cet prown:\n",
      "To of wout the you, misper:\n",
      "Unrhat this mitp dotly! the comink cim nat I dreto as fie yir,\n",
      "Buntle.\n",
      "OF IID:\n",
      "Vead,\n",
      "'Is but fraw motiesseris is is ther it leark.\n",
      "\n",
      "UCKE:\n",
      "Tit freartav\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(m.generate(idx, max_new_token=500)[0].tolist())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d61aaef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layer = 6\n",
    "n_head = 6\n",
    "n_embd = 384\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class BigramLanguageModel4(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reas off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        \n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_embed = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_embed = self.position_embedding_table(torch.arange(T)) # (T,C)\n",
    "        x = tok_embed + pos_embed # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_token):\n",
    "        # idx is (B, T) array of indices in the ctx\n",
    "        for _ in range(max_new_token):\n",
    "            idx_conds = idx[:, -block_size:]\n",
    "            # get predictions    \n",
    "            logits, loss = self(idx_conds)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax\n",
    "            probs = F.softmax(logits, dim=-1) # (B,C)\n",
    "            # sample from distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B,1)\n",
    "            # append \n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "    \n",
    "m = BigramLanguageModel4()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d7d86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
    "batch_size = 32 # how many independent sequences will we process in parallel?\n",
    "block_size = 8 # what is the maximum context length for predictions?\n",
    "\n",
    "for steps in range(10000):\n",
    "    \n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "    \n",
    "    # evaluate th eloss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac189a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(m.generate(idx, max_new_token=500)[0].tolist())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c27df08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
