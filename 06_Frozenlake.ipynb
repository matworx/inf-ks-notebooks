{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frozenlake\n",
    "\n",
    "Import relevant modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import (absolute_import, division, print_function, unicode_literals)\n",
    "\n",
    "import gym\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the policy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_policy(env):\n",
    "    \"\"\"Run a random policy for the given environment.\n",
    "    Logs the total reward and the number of steps until the terminal\n",
    "    state was reached.\n",
    "    Parameters\n",
    "    ----------\n",
    "    env: gym.envs.Environment\n",
    "      Instance of an OpenAI gym.\n",
    "    Returns\n",
    "    -------\n",
    "    (float, int)\n",
    "      First number is the total undiscounted reward received. The\n",
    "      second number is the total number of actions taken before the\n",
    "      episode finished.\n",
    "    \"\"\"\n",
    "    env.reset()\n",
    "    env.render()\n",
    "    time.sleep(1)  # just pauses so you can see the output\n",
    "\n",
    "    total_reward = 0\n",
    "    num_steps = 0\n",
    "\n",
    "    while True:\n",
    "        observation, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "        print(env.render())\n",
    "\n",
    "        total_reward += reward\n",
    "        num_steps += 1\n",
    "\n",
    "        if terminated:\n",
    "            break\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "    return total_reward, num_steps\n",
    "\n",
    "\n",
    "def print_env_info(env):\n",
    "    print('Environment has %s states and %s actions.' % (env.observation_space, env.action_space))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment has Discrete(16) states and Discrete(4) actions.\n",
      "  (Up)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "  (Right)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "  (Up)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "  (Up)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "  (Down)\n",
      "SFFF\n",
      "F\u001b[41mH\u001b[0mFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "Agent received total reward of: 0.000000\n",
      "Agent took 5 steps\n"
     ]
    }
   ],
   "source": [
    "# create the environment\n",
    "env = gym.make('FrozenLake-v1', is_slippery= False, render_mode=\"ansi\")\n",
    "\n",
    "print_env_info(env)\n",
    "\n",
    "total_reward, num_steps = run_random_policy(env)\n",
    "\n",
    "print('Agent received total reward of: %f' % total_reward)\n",
    "print('Agent took %d steps' % num_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Down)\n",
      "SFFF\n",
      "F\u001b[41mH\u001b[0mFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(env.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
